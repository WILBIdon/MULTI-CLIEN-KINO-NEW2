#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script para analizar la base de datos SQL de KINO
y detectar problemas con c√≥digos asignados a PDFs
"""

import re
import sqlite3
from collections import defaultdict, Counter
from pathlib import Path

def parse_sql_file(sql_file):
    """Parse el archivo SQL y extrae datos de documentos y c√≥digos"""
    
    with open(sql_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Extraer documentos
    docs_pattern = r"INSERT INTO `documents` \(`id`, `name`, `date`, `path`, `codigos_extraidos`\) VALUES\s*((?:\([^;]+\)[,;]?\s*)+)"
    docs_match = re.search(docs_pattern, content, re.MULTILINE | re.DOTALL)
    
    documents = {}
    if docs_match:
        docs_data = docs_match.group(1)
        # Parsear cada l√≠nea de documento
        doc_pattern = r"\((\d+),\s*'([^']+)',\s*'([^']+)',\s*'([^']+)',\s*(NULL|'[^']*')\)"
        for match in re.finditer(doc_pattern, docs_data):
            doc_id = int(match.group(1))
            documents[doc_id] = {
                'id': doc_id,
                'name': match.group(2),
                'date': match.group(3),
                'path': match.group(4),
                'codigos_extraidos': match.group(5)
            }
    
    # Extraer c√≥digos
    codes_pattern = r"INSERT INTO `codes` \(`id`, `document_id`, `code`\) VALUES\s*((?:\([^;]+\)[,;]?\s*)+)"
    codes_matches = re.findall(codes_pattern, content, re.MULTILINE | re.DOTALL)
    
    codes = []
    for codes_chunk in codes_matches:
        code_pattern = r"\((\d+),\s*(\d+),\s*'([^']+)'\)"
        for match in re.finditer(code_pattern, codes_chunk):
            codes.append({
                'id': int(match.group(1)),
                'document_id': int(match.group(2)),
                'code': match.group(3)
            })
    
    return documents, codes

def analyze_database(documents, codes):
    """Analiza la base de datos y genera reportes de problemas"""
    
    print("="*80)
    print("üîç AN√ÅLISIS DE BASE DE DATOS KINO")
    print("="*80)
    print()
    
    # Estad√≠sticas generales
    print(f"üìä ESTAD√çSTICAS GENERALES:")
    print(f"   Total de documentos: {len(documents)}")
    print(f"   Total de c√≥digos: {len(codes)}")
    print()
    
    # Agrupar c√≥digos por documento
    codes_by_doc = defaultdict(list)
    for code in codes:
        codes_by_doc[code['document_id']].append(code['code'])
    
    # An√°lisis 1: Documentos sin c√≥digos
    print("‚ö†Ô∏è  DOCUMENTOS SIN C√ìDIGOS ASIGNADOS:")
    docs_without_codes = []
    for doc_id, doc in documents.items():
        if doc_id not in codes_by_doc or len(codes_by_doc[doc_id]) == 0:
            docs_without_codes.append(doc)
            print(f"   ID {doc_id}: {doc['name']} ({doc['path']})")
    
    if not docs_without_codes:
        print("   ‚úÖ Todos los documentos tienen c√≥digos asignados")
    print()
    
    # An√°lisis 2: C√≥digos duplicados
    print("üîÑ C√ìDIGOS DUPLICADOS (mismo c√≥digo en m√∫ltiples documentos):")
    all_codes_with_docs = [(code['code'], code['document_id']) for code in codes]
    code_occurrences = defaultdict(list)
    for code, doc_id in all_codes_with_docs:
        code_occurrences[code].append(doc_id)
    
    duplicates = {code: docs for code, docs in code_occurrences.items() if len(docs) > 1}
    
    if duplicates:
        duplicate_count = 0
        for code, doc_ids in sorted(duplicates.items()):
            if duplicate_count < 20:  # Mostrar solo los primeros 20
                doc_names = [documents[did]['name'] for did in doc_ids if did in documents]
                print(f"   C√≥digo '{code}' aparece en {len(doc_ids)} documentos:")
                for doc_id in doc_ids:
                    if doc_id in documents:
                        print(f"      - Doc ID {doc_id}: {documents[doc_id]['name']}")
                print()
                duplicate_count += 1
        
        if len(duplicates) > 20:
            print(f"   ... y {len(duplicates) - 20} c√≥digos duplicados m√°s")
        
        print(f"   üìà RESUMEN: {len(duplicates)} c√≥digos √∫nicos est√°n duplicados")
    else:
        print("   ‚úÖ No hay c√≥digos duplicados")
    print()
    
    # An√°lisis 3: Documentos con m√°s c√≥digos
    print("üìë TOP 10 DOCUMENTOS CON M√ÅS C√ìDIGOS:")
    docs_with_counts = [(doc_id, len(codes_by_doc[doc_id])) for doc_id in codes_by_doc]
    docs_with_counts.sort(key=lambda x: x[1], reverse=True)
    
    for i, (doc_id, count) in enumerate(docs_with_counts[:10], 1):
        if doc_id in documents:
            print(f"   {i}. {documents[doc_id]['name']}: {count} c√≥digos")
    print()
    
    # An√°lisis 4: C√≥digos con patrones extra√±os
    print("üö® C√ìDIGOS CON PATRONES POTENCIALMENTE PROBLEM√ÅTICOS:")
    suspicious_codes = []
    
    for code_entry in codes:
        code = code_entry['code']
        # Detectar c√≥digos muy cortos o muy largos
        if len(code) < 2:
            suspicious_codes.append((code, code_entry['document_id'], "C√≥digo muy corto"))
        elif len(code) > 30:
            suspicious_codes.append((code, code_entry['document_id'], "C√≥digo muy largo"))
        # Detectar c√≥digos con caracteres extra√±os
        elif not re.match(r'^[A-Za-z0-9:\-+/.()]+$', code):
            suspicious_codes.append((code, code_entry['document_id'], "Caracteres especiales"))
    
    if suspicious_codes:
        for i, (code, doc_id, reason) in enumerate(suspicious_codes[:15], 1):
            if doc_id in documents:
                print(f"   {i}. '{code}' en Doc ID {doc_id} ({documents[doc_id]['name']}) - {reason}")
        if len(suspicious_codes) > 15:
            print(f"   ... y {len(suspicious_codes) - 15} c√≥digos sospechosos m√°s")
    else:
        print("   ‚úÖ No se detectaron c√≥digos con patrones problem√°ticos")
    print()
    
    # An√°lisis 5: IDs de documentos faltantes en tabla codes
    print("üîç VERIFICACI√ìN DE INTEGRIDAD REFERENCIAL:")
    doc_ids_referenced = set(code['document_id'] for code in codes)
    missing_docs = doc_ids_referenced - set(documents.keys())
    
    if missing_docs:
        print(f"   ‚ö†Ô∏è  C√≥digos hacen referencia a {len(missing_docs)} documentos que NO EXISTEN:")
        for doc_id in sorted(missing_docs)[:10]:
            codes_for_missing = [c['code'] for c in codes if c['document_id'] == doc_id]
            print(f"      Doc ID {doc_id}: {len(codes_for_missing)} c√≥digos hu√©rfanos")
            print(f"         Ejemplos: {', '.join(codes_for_missing[:5])}")
    else:
        print("   ‚úÖ Todos los c√≥digos referencian documentos existentes")
    print()
    
    # Retornar datos para an√°lisis adicional
    return {
        'duplicates': duplicates,
        'docs_without_codes': docs_without_codes,
        'codes_by_doc': dict(codes_by_doc),
        'suspicious_codes': suspicious_codes,
        'missing_doc_refs': missing_docs
    }

if __name__ == '__main__':
    sql_file = r'c:\Users\Usuario\Desktop\kino-trace\if0_39064130_buscador (10).sql'
    
    print("Cargando y parseando archivo SQL...")
    documents, codes = parse_sql_file(sql_file)
    
    print(f"‚úÖ Cargados {len(documents)} documentos y {len(codes)} c√≥digos")
    print()
    
    analysis = analyze_database(documents, codes)
    
    print("="*80)
    print("‚úÖ AN√ÅLISIS COMPLETADO")
    print("="*80)
